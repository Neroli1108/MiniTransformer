{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, src_pad_idx, trg_pad_idx, enc_voc_size, max_len, dec_voc_size, d_model, n_heads, ffn_hidden, n_layers, drop_prob, device):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.src_pad_idx = src_pad_idx\n",
    "        self.trg_pad_idx = trg_pad_idx\n",
    "        self.device = device\n",
    "        self.encoder = Encoder(enc_voc_size, max_len, d_model, ffn_hidden, n_heads, n_layers, device, drop_prob)\n",
    "        self.decoder = Decoder(dec_voc_size, max_len, d_model, ffn_hidden, n_heads, n_layers, drop_prob, device)\n",
    "        self.projection = nn.Linear(d_model, dec_voc_size)\n",
    "\n",
    "    def make_pad_mask(self, q, k, pad_idx_q, pad_idx_k):\n",
    "        len_q, len_k = q.size(1), k.size(1)\n",
    "        k = k.ne(pad_idx_k).unsqueeze(1).unsqueeze(3)\n",
    "        k = k.repeat(1, 1, len_q, 1)\n",
    "        q = q.ne(pad_idx_q).unsqueeze(1).unsqueeze(3)\n",
    "        q = q.repeat(1, 1, 1, len_k)\n",
    "        mask = k & q\n",
    "        return mask\n",
    "\n",
    "    def make_casual_mask(self, q, k):\n",
    "        mask = torch.tril(torch.ones(q.size(1), k.size(1))).type(torch.BoolTensor).to(self.device)\n",
    "        return mask\n",
    "\n",
    "    def forward(self, src, trg):\n",
    "        src_mask = self.make_pad_mask(src, src, self.src_pad_idx, self.src_pad_idx)\n",
    "        trg_mask = self.make_pad_mask(src, src, self.src_pad_idx, self.src_pad_idx) * self.make_casual_mask(trg, trg)\n",
    "        enc = self.encoder(src, src_mask)\n",
    "        output = self.decoder(trg, enc, trg_mask, src_mask)\n",
    "        return output\n",
    "       \n",
    "                 \n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
